{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d08fd03c",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center\">Space Debris Detection using detection transformer with custom backbone</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56630b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import DetrForObjectDetection, DetrImageProcessor\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "706cb140",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"debris_det_dataset\"\n",
    "\n",
    "ANNOTATION_FILE_NAME = \"_annotations.coco.json\"\n",
    "TRAIN_DIR = os.path.join(dataset_path, \"train\")\n",
    "VAL_DIR = os.path.join(dataset_path, \"valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7cc7861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.11s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Number of training samples: 20000\n",
      "Number of validation samples: 2000\n"
     ]
    }
   ],
   "source": [
    "class CocoDetection(torchvision.datasets.CocoDetection):\n",
    "    def __init__(self, image_dir_path:str, image_processor, train:bool=True):\n",
    "        annot_file_path = os.path.join(image_dir_path, ANNOTATION_FILE_NAME)\n",
    "        super(CocoDetection, self).__init__(image_dir_path, annot_file_path)\n",
    "        self.image_processor = image_processor\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        images, annotations = super(CocoDetection, self).__getitem__(idx)\n",
    "        image_id = self.ids[idx]\n",
    "        annotations = {'image_id': image_id, 'annotations': annotations}\n",
    "        encoding = self.image_processor(images=images, annotations=annotations, return_tensors=\"pt\")\n",
    "        pixel_values = encoding['pixel_values'].squeeze()\n",
    "        target = encoding['labels'][0]\n",
    "        return pixel_values, target\n",
    "    \n",
    "\n",
    "TRAIN_DATASET = CocoDetection(TRAIN_DIR, DetrImageProcessor.from_pretrained(\"facebook/detr-resnet-50\"), train=True)\n",
    "VAL_DATASET = CocoDetection(VAL_DIR, DetrImageProcessor.from_pretrained(\"facebook/detr-resnet-50\"), train=False)\n",
    "\n",
    "print(f\"Number of training samples: {len(TRAIN_DATASET)}\")\n",
    "print(f\"Number of validation samples: {len(VAL_DATASET)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96443085",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    pixel_values = [item[0] for item in batch]\n",
    "    encoding = DetrImageProcessor.from_pretrained(\"facebook/detr-resnet-50\").pad(pixel_values, return_tensors=\"pt\")\n",
    "    labels = [item[1] for item in batch]\n",
    "    return {'pixel_values': encoding['pixel_values'], 'pixel_mask': encoding['pixel_mask'], 'labels': labels}\n",
    "\n",
    "\n",
    "TRAIN_DATALOADER = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolotiny_01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
